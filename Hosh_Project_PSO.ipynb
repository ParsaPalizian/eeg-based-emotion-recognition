{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0fc99470",
      "metadata": {
        "id": "0fc99470"
      },
      "source": [
        "# Including Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5e31739c",
      "metadata": {
        "id": "5e31739c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import loadmat\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import random\n",
        "from tensorflow import keras\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "preprocessing.LabelEncoder()\n",
        "import random\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from tensorflow import keras\n",
        "from keras import layers, Sequential\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras import backend as K\n",
        "from keras.utils import  to_categorical\n",
        "from sklearn.model_selection import KFold\n",
        "from scipy.io import loadmat\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f6b39fb",
      "metadata": {
        "id": "5f6b39fb"
      },
      "source": [
        "# Reading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc -O dataset.zip https://www.dropbox.com/scl/fo/9ppie6m2voe9s68ato4iv/h?rlkey=m23k38d3xka34l9kdytpxm0ex&dl=0\n",
        "!unzip -n -d dataset dataset.zip\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJIUXaDOFWEa",
        "outputId": "f2e0c084-0052-4a75-845a-621646d4ba2f"
      },
      "id": "EJIUXaDOFWEa",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-03 18:06:02--  https://www.dropbox.com/scl/fo/9ppie6m2voe9s68ato4iv/h?rlkey=m23k38d3xka34l9kdytpxm0ex\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:601b:18::a27d:812\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucbdaf91c698a1904bd8ed338e71.dl.dropboxusercontent.com/zip_download_get/Bv81r4cl5aJ6_TZcHQsLm6kqAHtbs9HBPXP8voe4YU9V-I5ZUOIol3np9BHp-fLI2v32Q3BAhxN_M0MDXDvU0_KYIVVgfoVrkrePbV64uIjp8w# [following]\n",
            "--2024-02-03 18:06:03--  https://ucbdaf91c698a1904bd8ed338e71.dl.dropboxusercontent.com/zip_download_get/Bv81r4cl5aJ6_TZcHQsLm6kqAHtbs9HBPXP8voe4YU9V-I5ZUOIol3np9BHp-fLI2v32Q3BAhxN_M0MDXDvU0_KYIVVgfoVrkrePbV64uIjp8w\n",
            "Resolving ucbdaf91c698a1904bd8ed338e71.dl.dropboxusercontent.com (ucbdaf91c698a1904bd8ed338e71.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\n",
            "Connecting to ucbdaf91c698a1904bd8ed338e71.dl.dropboxusercontent.com (ucbdaf91c698a1904bd8ed338e71.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 983945844 (938M) [application/zip]\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip         100%[===================>] 938.36M   129MB/s    in 11s     \n",
            "\n",
            "2024-02-03 18:06:14 (88.8 MB/s) - ‘dataset.zip’ saved [983945844/983945844]\n",
            "\n",
            "Archive:  dataset.zip\n",
            "warning:  stripped absolute path spec from /\n",
            "mapname:  conversion of  failed\n",
            " extracting: dataset/Project_data.mat  \n",
            " extracting: dataset/EEGbased emotion recognition in an immersive virtual reality environment From local activity to brain network features.pdf  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = loadmat('dataset/Project_data.mat')"
      ],
      "metadata": {
        "id": "_XVKCFzlFZ1u"
      },
      "id": "_XVKCFzlFZ1u",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = dataset['TrainLabels'].T\n",
        "y[ y == -1] = 0"
      ],
      "metadata": {
        "id": "lNGSxiXDFa84"
      },
      "id": "lNGSxiXDFa84",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"features_count.csv\" )\n",
        "X = df"
      ],
      "metadata": {
        "id": "g3oKzSqbFdMe"
      },
      "id": "g3oKzSqbFdMe",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGo4nGiWKQWk",
        "outputId": "aae53f8b-ae97-4506-e243-f76cb84846c0"
      },
      "id": "qGo4nGiWKQWk",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(550, 3009)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "X1 = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "_Xm5r2maK5ut"
      },
      "id": "_Xm5r2maK5ut",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLWivojFLKkm",
        "outputId": "d411efb2-c6f1-4c38-9e96-bb0af83f9947"
      },
      "id": "qLWivojFLKkm",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(550, 3009)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JyOooToLQpa",
        "outputId": "60c47d22-51d9-466f-b537-f1c5296ffe36"
      },
      "id": "9JyOooToLQpa",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyswarms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kpu8cgSZjQS",
        "outputId": "1e2c46f1-957e-4b9f-adb0-9ebf4132822a"
      },
      "id": "6kpu8cgSZjQS",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyswarms\n",
            "  Downloading pyswarms-1.3.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyswarms) (1.11.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyswarms) (1.23.5)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pyswarms) (3.7.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from pyswarms) (23.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pyswarms) (4.66.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyswarms) (0.18.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from pyswarms) (6.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.3.1->pyswarms) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.3.1->pyswarms) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.3.1->pyswarms) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.3.1->pyswarms) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.3.1->pyswarms) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.3.1->pyswarms) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.3.1->pyswarms) (1.16.0)\n",
            "Installing collected packages: pyswarms\n",
            "Successfully installed pyswarms-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X1"
      ],
      "metadata": {
        "id": "heEfikfEbub_"
      },
      "id": "heEfikfEbub_",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQSBGx2cLUIL",
        "outputId": "be0b5e51-eb0d-4ef9-f7a4-30ecfd7de05c"
      },
      "id": "sQSBGx2cLUIL",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(550, 3009)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_num_features  = 50"
      ],
      "metadata": {
        "id": "cRpUHVrpYlht"
      },
      "id": "cRpUHVrpYlht",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create an instance of the classifier\n",
        "classifier = linear_model.LogisticRegression()\n",
        "#classifier = RandomForestClassifier(n_estimators = 64,\n",
        "#                                    #max_features = 30,\n",
        "#                                    bootstrap = True,\n",
        "#                                    random_state = None)\n",
        "\n",
        "#clf = forest\n",
        "#clf.fit(X_trainOhFeatures, y_train)\n",
        "#predictions = clf.predict(X_testOhFeatures)\n",
        "#accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "\n",
        "# Define objective function\n",
        "def f_per_particle(m, alpha):\n",
        "    \"\"\"Computes for the objective function per particle\n",
        "\n",
        "    Inputs\n",
        "    ------\n",
        "    m : numpy.ndarray\n",
        "        Binary mask that can be obtained from BinaryPSO, will\n",
        "        be used to mask features.\n",
        "    alpha: float (default is 0.5)\n",
        "        Constant weight for trading-off classifier performance\n",
        "        and number of features\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    numpy.ndarray\n",
        "        Computed objective function\n",
        "    \"\"\"\n",
        "    total_features = X.shape[1]\n",
        "    # Get the subset of the features from the binary mask\n",
        "    if np.count_nonzero(m) == 0:\n",
        "        #if the particle subset is only zeros, get the original set of attributes\n",
        "        X_subset = X\n",
        "    else:\n",
        "        X_subset = X[:,m==1]\n",
        "\n",
        "    #X_train, X_test, y_train, y_test = train_test_split(X_subset, y, test_size=0.20, random_state=None)\n",
        "    # Perform classification and store performance in P\n",
        "    #classifier.fit(X_train, y_train)\n",
        "    #P = (classifier.predict(X_test) == y_test).mean()\n",
        "\n",
        "    scores = cross_val_score(classifier, X_subset, y, cv=3)\n",
        "    #print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "\n",
        "    P = scores.mean()\n",
        "    particleScore.append(P)\n",
        "    particleSize.append(X_subset.shape[1])\n",
        "    # Compute for the objective function\n",
        "    #j = (alpha * (1.0 - P)+ (1.0 - alpha) * (1 - (X_subset.shape[1] / total_features)))\n",
        "\n",
        "    j = (alpha * (1.0 - P)) + (1 - alpha) * (1 - (total_features - X_subset.shape[1]) / total_features)\n",
        "    #print(\"Particle j: \", j)\n",
        "    return j"
      ],
      "metadata": {
        "id": "NzEqsRH2Zcg0"
      },
      "id": "NzEqsRH2Zcg0",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create an instance of the classifier\n",
        "classifier = linear_model.LogisticRegression()\n",
        "# classifier = RandomForestClassifier(n_estimators = 64,\n",
        "#                                    max_features = max_num_features,\n",
        "#                                    bootstrap = True,\n",
        "#                                    random_state = None)\n",
        "\n",
        "#clf = forest\n",
        "#clf.fit(X_trainOhFeatures, y_train)\n",
        "#predictions = clf.predict(X_testOhFeatures)\n",
        "#accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "\n",
        "# Define objective function\n",
        "def f_per_particle1(m, alpha):\n",
        "    total_features = X.shape[1]\n",
        "    if np.count_nonzero(m) == 0:\n",
        "        X_subset = X\n",
        "    else:\n",
        "        X_subset = X[:,m==1]\n",
        "\n",
        "    classifier.fit(X_subset, y)\n",
        "    P = (classifier.predict(X_subset) == y).mean()\n",
        "\n",
        "    features_count = np.count_nonzero(m)\n",
        "    features_overflow = np.clip( max_num_features - features_count, 0, 10)\n",
        "    feature_overflow_penalty = (features_overflow / 10)\n",
        "    j = (alpha * (1.0 - P)+ (1.0 - alpha) * (1 - (X_subset.shape[1] / total_features))) - feature_overflow_penalty\n",
        "\n",
        "    return j\n",
        "    return j"
      ],
      "metadata": {
        "id": "WDr0xPMGehR2"
      },
      "id": "WDr0xPMGehR2",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x, alpha=0.9):\n",
        "    \"\"\"Higher-level method to do classification in the\n",
        "    whole swarm.\n",
        "\n",
        "    Inputs\n",
        "    ------\n",
        "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
        "        The swarm that will perform the search\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    numpy.ndarray of shape (n_particles, )\n",
        "        The computed loss for each particle\n",
        "    \"\"\"\n",
        "    n_particles = x.shape[0]\n",
        "    j = [f_per_particle(x[i], alpha) for i in range(n_particles)]\n",
        "    #print(\"f j: \", j)\n",
        "    return np.array(j)"
      ],
      "metadata": {
        "id": "vsPGh54kZWW1"
      },
      "id": "vsPGh54kZWW1",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime as dt\n",
        "import time\n",
        "import pyswarms as ps\n",
        "start = dt.now()\n",
        "print(\"Started at: \", str(start))\n",
        "particleScore = list()\n",
        "particleSize = list()\n",
        "#mySubsets = list()\n",
        "\n",
        "# Initialize swarm, arbitrary\n",
        "options = {'c1': 2, 'c2': 2, 'w':0.3, 'k': 20, 'p':2}\n",
        "\n",
        "# Call instance of PSO\n",
        "dimensions = X.shape[1] # dimensions should be the number of features\n",
        "#optimizer.reset()\n",
        "# optimizer = ps.single.GlobalBestPSO(n_particles=1, dimensions=dimensions,options=options)\n",
        "optimizer = ps.discrete.BinaryPSO(n_particles=20, dimensions=dimensions, options=options)\n",
        "\n",
        "# Perform optimization\n",
        "# cost, pos = optimizer.optimize(f, iters=10, verbose=2)\n",
        "# cost, pos = optimizer.optimize(f, print_step=100, iters=1000, verbose=2)\n",
        "cost, pos = optimizer.optimize(f,iters=100 )\n",
        "\n",
        "\n",
        "#print(cost,pos)\n",
        "end = dt.now()\n",
        "print(\"Finished at: \", str(end))\n",
        "total = end-start\n",
        "print(\"Total time spent: \", total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNPmiR2eMxu1",
        "outputId": "ad5b12d8-595d-4b35-dd77-2a5b4245be11"
      },
      "id": "KNPmiR2eMxu1",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-03 18:14:05,063 - pyswarms.discrete.binary - INFO - Optimize for 100 iters with {'c1': 2, 'c2': 2, 'w': 0.3, 'k': 20, 'p': 2}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started at:  2024-02-03 18:14:05.025972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pyswarms.discrete.binary: 100%|██████████|100/100, best_cost=0.186\n",
            "2024-02-03 18:28:27,703 - pyswarms.discrete.binary - INFO - Optimization finished | best cost: 0.18559358453506197, best pos: [0 1 1 ... 1 1 0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished at:  2024-02-03 18:28:27.705958\n",
            "Total time spent:  0:14:22.679986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two instances of LogisticRegression\n",
        "classfier = linear_model.LogisticRegression()\n",
        "\n",
        "# Get the selected features from the final positions\n",
        "X_selected_features = X[:,pos==1]  # subset\n",
        "\n",
        "# Perform classification and store performance in P\n",
        "classifier.fit(X_selected_features, y)\n",
        "\n",
        "# Compute performance\n",
        "subset_performance = (classifier.predict(X_selected_features) == y).mean()\n",
        "\n",
        "\n",
        "print('Subset performance: %.3f' % (subset_performance))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljbNV0gpb_BW",
        "outputId": "24cc8693-bb8f-4486-8c23-9f1ec10f07f6"
      },
      "id": "ljbNV0gpb_BW",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset performance: 0.500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(optimizer.mean_pbest_history)\n",
        "pos =np.array(optimizer.pos_history)\n",
        "pos.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iF6T3IyZfAY",
        "outputId": "512d1075-752c-483c-ff6e-336f478a1f19"
      },
      "id": "_iF6T3IyZfAY",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.2249319409317782, 0.21626569477834018, 0.20840759439429393, 0.2083848756652352, 0.2083848756652352, 0.20795199561093386, 0.20795199561093386, 0.20700226683930154, 0.20565600359766503, 0.2044534941741655, 0.2044534941741655, 0.2044534941741655, 0.2044534941741655, 0.20436919388543795, 0.20401130905809534, 0.20401130905809534, 0.20401130905809534, 0.20344497053505672, 0.203438868622216, 0.2019341863042377, 0.2019341863042377, 0.20187449234619734, 0.20187449234619734, 0.2015178300925212, 0.20117120055253582, 0.20117120055253582, 0.20117120055253582, 0.20101435832677778, 0.20101435832677778, 0.20101435832677778, 0.1993861572801197, 0.19884995494628016, 0.19878938454889544, 0.19845817145853953, 0.19843292097454368, 0.19843292097454368, 0.19837054780656843, 0.19837054780656843, 0.19837054780656843, 0.19837054780656843, 0.19837054780656843, 0.19837054780656843, 0.19837054780656843, 0.19837054780656843, 0.19837054780656843, 0.19803072828911697, 0.19803072828911697, 0.19747247862020972, 0.19742161700927155, 0.19742161700927155, 0.19742161700927155, 0.19707749198354094, 0.19707749198354094, 0.19707749198354094, 0.19704095586251463, 0.19704095586251463, 0.19704095586251463, 0.19704095586251463, 0.19693506007873268, 0.19693506007873268, 0.19692454517535538, 0.1963025922825489, 0.1963025922825489, 0.1963025922825489, 0.1963025922825489, 0.1963025922825489, 0.1963025922825489, 0.1963025922825489, 0.1963025922825489, 0.1963025922825489, 0.1963025922825489, 0.1963025922825489, 0.1963025922825489, 0.1963025922825489, 0.1963025922825489, 0.1963025922825489, 0.1963025922825489, 0.1963025922825489, 0.19593350664921366, 0.19593350664921366, 0.19548369088505452, 0.19548369088505452, 0.19548369088505452, 0.19548369088505452, 0.19548369088505452, 0.19548369088505452, 0.19548369088505452, 0.19548369088505452, 0.19548369088505452, 0.19548369088505452, 0.19548369088505452, 0.19548369088505452, 0.1953836438534243, 0.1953836438534243, 0.1953836438534243, 0.1953836438534243, 0.1953836438534243, 0.1953836438534243, 0.19497346165352838, 0.19486359198716513]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 20, 3009)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_selected_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOu4zR1GgY6w",
        "outputId": "ce0e6ccb-bfa2-4ae0-e43f-bb007e835f17"
      },
      "id": "JOu4zR1GgY6w",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(550, 1497)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X= X_selected_features"
      ],
      "metadata": {
        "id": "jOD93_ackffB"
      },
      "id": "jOD93_ackffB",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_mlp_sigmoid = Sequential([\n",
        "    layers.InputLayer(input_shape=(X_selected_features.shape[1],)),\n",
        "    layers.Dense(units = 32 , activation = \"relu\"),\n",
        "    layers.Dense(units = 32 , activation = \"relu\"),\n",
        "    layers.Dense(units = 1 , activation = \"sigmoid\"),\n",
        "])\n"
      ],
      "metadata": {
        "id": "AwIMlptfZC-t"
      },
      "id": "AwIMlptfZC-t",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_mlp_sigmoid.compile(optimizer = \"adam\" , loss = \"binary_crossentropy\" , metrics = [\"accuracy\", \"binary_accuracy\"])"
      ],
      "metadata": {
        "id": "thdqxwkhZEFN"
      },
      "id": "thdqxwkhZEFN",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5)\n",
        "# kf.get_n_splits(X)\n",
        "histories =  []\n",
        "histories_mlp_sigmoid =[]\n",
        "histories_mlp_softmax =[]\n",
        "histories_rbf_1_sigmoid =[]\n",
        "histories_rbf_1_softmax =[]\n",
        "histories_rbf_2_sigmoid =[]\n",
        "fold_accuracies = []\n",
        "kf.get_n_splits(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRkHQpWyZGdE",
        "outputId": "e7a03207-6d41-4020-b3af-b8b125646216"
      },
      "id": "bRkHQpWyZGdE",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30"
      ],
      "metadata": {
        "id": "DIlIu3Z3Zfhc"
      },
      "id": "DIlIu3Z3Zfhc",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train = X[train_index , :]\n",
        "    y_train = y[train_index , :]\n",
        "    X_valid = X[test_index , :]\n",
        "    y_valid = y[test_index , :]\n",
        "    y_categorized = to_categorical(y)\n",
        "    y_train_categorized = y_categorized[train_index , :]\n",
        "    y_valid_categorized = y_categorized[test_index , :]\n",
        "    #TODO after import Data open codes\n",
        "    print(f\"##################### Fold :{i} started #####################\")\n",
        "    print(\"MLP sigmoid started\")\n",
        "    history_mlp_sigmoid = model_mlp_sigmoid.fit(X_train , y_train , epochs= epochs , validation_data = (X_valid, y_valid), verbose = 0)\n",
        "    print(\"MLP sigmoid finished\")\n",
        "    histories_mlp_sigmoid.append(history_mlp_sigmoid)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq_zaX7OZUGV",
        "outputId": "9e923119-25f4-4331-ad60-9ef1d783f1fd"
      },
      "id": "jq_zaX7OZUGV",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##################### Fold :0 started #####################\n",
            "MLP sigmoid started\n",
            "MLP sigmoid finished\n",
            "##################### Fold :1 started #####################\n",
            "MLP sigmoid started\n",
            "MLP sigmoid finished\n",
            "##################### Fold :2 started #####################\n",
            "MLP sigmoid started\n",
            "MLP sigmoid finished\n",
            "##################### Fold :3 started #####################\n",
            "MLP sigmoid started\n",
            "MLP sigmoid finished\n",
            "##################### Fold :4 started #####################\n",
            "MLP sigmoid started\n",
            "MLP sigmoid finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"############################### FOLDS Accuracy ###############################\")\n",
        "print(\"--------SIGMOID MLP\")\n",
        "for m in histories_mlp_sigmoid:\n",
        "    print(max(m.history[\"val_accuracy\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRFgZfGRZlTU",
        "outputId": "717d979a-3985-4045-9a1b-555363713ff0"
      },
      "id": "cRFgZfGRZlTU",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############################### FOLDS Accuracy ###############################\n",
            "--------SIGMOID MLP\n",
            "0.800000011920929\n",
            "0.9272727370262146\n",
            "0.9909090995788574\n",
            "1.0\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"############################### Average Accuracy ###############################\")\n",
        "print(\"--------SIGMOID MLP\")\n",
        "print(sum([ max(m.history[\"val_accuracy\"]) for m in  histories_mlp_sigmoid]) / 5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQtJe4LvZpne",
        "outputId": "5cb564d7-6363-4c95-c0eb-0f063f21a634"
      },
      "id": "iQtJe4LvZpne",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############################### Average Accuracy ###############################\n",
            "--------SIGMOID MLP\n",
            "0.9436363697052002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3GxjCoy9knPq"
      },
      "id": "3GxjCoy9knPq",
      "execution_count": 60,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}